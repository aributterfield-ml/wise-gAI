{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1nVkQc28qshNuiatUAzesfDAknn74rH5h","timestamp":1736446665626}],"gpuType":"T4","mount_file_id":"1JKlsPHPGDqPC5U6rcBJbdMur4jzuTJv5","authorship_tag":"ABX9TyOpQCesmBpUm4O4WGFJZ9Yi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"1aZoQuv5BWKB"}},{"cell_type":"code","source":["# Install necessary libraries\n","!pip install transformers datasets torch accelerate sentence-transformers --quiet"],"metadata":{"id":"aMZjgF5afYNd","executionInfo":{"status":"ok","timestamp":1740543542279,"user_tz":360,"elapsed":114426,"user":{"displayName":"Ari","userId":"13742471207560721672"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"717f9d1f-4f9b-454e-d71d-b15ee6d165df"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer, util\n","import pandas as pd\n","import torch\n","import re\n","import importlib.util\n","import sys\n","from pathlib import Path\n","from transformers import pipeline\n","from datasets import Dataset\n","from tqdm import tqdm\n","import numpy as np"],"metadata":{"id":"TIsX7l5AclY8","executionInfo":{"status":"ok","timestamp":1740543575458,"user_tz":360,"elapsed":33183,"user":{"displayName":"Ari","userId":"13742471207560721672"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Define the path to topics.py\n","topics_file_path = Path(\"drive/MyDrive/topics.py\")  # Replace with the actual file path\n","\n","# Dynamically import topics.py\n","spec = importlib.util.spec_from_file_location(\"topics\", topics_file_path)\n","topics_module = importlib.util.module_from_spec(spec)\n","sys.modules[\"topics\"] = topics_module\n","spec.loader.exec_module(topics_module)"],"metadata":{"id":"rqd4F3vBVCTs","executionInfo":{"status":"ok","timestamp":1740543576203,"user_tz":360,"elapsed":750,"user":{"displayName":"Ari","userId":"13742471207560721672"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Data Import and Processing"],"metadata":{"id":"mgRdCcZSfVY6"}},{"cell_type":"code","source":["proverbs_location = \"drive/MyDrive/merged_proverbs.txt\"\n","\n","# Read the entire file as a single string\n","with open(proverbs_location, 'r') as file:\n","    content = file.read()\n","\n","# Split the verses with 'Pro ' as the delimiter, and skip the first empty split\n","lines = content.split('Pro ')[1:]\n","\n","# Open the file and load each verse into a pandas dataframe\n","data = []\n","for line in lines:\n","    parts = line.split(' ', 1)\n","    chapter, verse = parts[0].split(':')\n","    text = parts[1]\n","    data.append([chapter, verse, text])\n","\n","# Create a DataFrame\n","proverbs_df = pd.DataFrame(data, columns=['chapter', 'verse', 'text'])\n","proverbs_df['book'] = \"Proverbs\""],"metadata":{"id":"lo5myOsyfYVf","collapsed":true,"executionInfo":{"status":"ok","timestamp":1740543577292,"user_tz":360,"elapsed":1083,"user":{"displayName":"Ari","userId":"13742471207560721672"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["proverbs_location = \"drive/MyDrive/merged_ecc.txt\"\n","\n","# Read the entire file as a single string\n","with open(proverbs_location, 'r') as file:\n","    content = file.read()\n","\n","# Split the verses with 'Pro ' as the delimiter, and skip the first empty split\n","lines = content.split('Ecc ')[1:]\n","\n","# Open the file and load each verse into a pandas dataframe\n","data = []\n","for line in lines:\n","    parts = line.split(' ', 1)\n","    chapter, verse = parts[0].split(':')\n","    text = parts[1]\n","    data.append([chapter, verse, text])\n","\n","# Create a DataFrame\n","ecc_df = pd.DataFrame(data, columns=['chapter', 'verse', 'text'])\n","ecc_df['book'] = \"Ecclesiastes\""],"metadata":{"id":"2dbjEb3htwDR","executionInfo":{"status":"ok","timestamp":1740543578240,"user_tz":360,"elapsed":944,"user":{"displayName":"Ari","userId":"13742471207560721672"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Annotations"],"metadata":{"id":"ShUspvqASeQy"}},{"cell_type":"code","source":["# Check GPU availability\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")\n","\n","# Configurations for efficient computation\n","BATCH_SIZE = 16  # Adjust batch size for free-tier GPU; lower if you hit memory issues.\n","# List of proverbs\n","proverbs = proverbs_df['text'].to_list() + ecc_df['text'].to_list()\n","\n","# List of topics\n","topics = topics_module.topics\n","\n","print(len(proverbs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39Ae-uzyU7E5","executionInfo":{"status":"ok","timestamp":1740543578322,"user_tz":360,"elapsed":63,"user":{"displayName":"Ari","userId":"13742471207560721672"}},"outputId":"31a1e8b0-9c63-4e6e-c7ff-9682c88daa6d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","734\n"]}]},{"cell_type":"code","source":["# Step 1: Pre-filter topics using SentenceTransformer embeddings\n","print(\"Generating embeddings for topics and proverbs...\")\n","embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # Efficient and fast model\n","\n","# Generate embeddings\n","topic_embeddings = embedding_model.encode(topics, convert_to_tensor=True, device=device)\n","proverb_embeddings = embedding_model.encode(proverbs, convert_to_tensor=True, device=device)\n","\n","# Pre-filter top 100 proverbs per topic\n","print(\"Filtering top proverbs for each topic...\")\n","filtered_proverbs = []  # Stores top 100 proverbs for each topic\n","top_n_proverbs = 100    # Reduce candidates to 100 per topic\n","\n","for topic_embedding in tqdm(topic_embeddings):\n","    cosine_scores = util.pytorch_cos_sim(topic_embedding, proverb_embeddings)[0]\n","    top_proverbs_idx = torch.topk(cosine_scores, k=top_n_proverbs).indices\n","    filtered_proverbs.append([proverbs[i] for i in top_proverbs_idx])\n","\n","# Step 2: Zero-shot classification using pre-filtered proverbs and faster model\n","print(\"Initializing zero-shot classifier...\")\n","classifier = pipeline(\"zero-shot-classification\", model=\"valhalla/distilbart-mnli-12-3\", device=0 if device == \"cuda\" else -1)\n","\n","# Batch process topics with pre-filtered proverbs\n","BATCH_SIZE = 16\n","results = []\n","\n","print(\"Classifying topics...\")\n","for i in tqdm(range(0, len(topics), BATCH_SIZE)):\n","    batch_topics = topics[i:i + BATCH_SIZE]\n","    batch_filtered_proverbs = filtered_proverbs[i:i + BATCH_SIZE]\n","\n","    for topic, proverbs_subset in zip(batch_topics, batch_filtered_proverbs):\n","        result = classifier(\n","            topic,\n","            candidate_labels=proverbs_subset,\n","            multi_label=True\n","        )\n","        # Get the top 5 proverbs\n","        top_proverbs = np.array(result[\"labels\"])[np.argsort(result[\"scores\"])[-5:]][::-1]\n","        for proverb in top_proverbs:\n","            results.append({\"topic\": topic, \"proverb\": proverb})\n","\n","# Step 3: Save results to a CSV file\n","df = pd.DataFrame(results)\n","df.to_csv(\"optimized_topic_proverb_matches.csv\", index=False)\n","\n","print(\"Matching complete. Results saved to 'optimized_topic_proverb_matches.csv'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xaYleHqsmWSG","executionInfo":{"status":"ok","timestamp":1740545416318,"user_tz":360,"elapsed":1322091,"user":{"displayName":"Ari","userId":"13742471207560721672"}},"outputId":"22bc162b-47b2-4253-c8d1-e5ff30fb819a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating embeddings for topics and proverbs...\n","Filtering top proverbs for each topic...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:01<00:00, 748.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Initializing zero-shot classifier...\n"]},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["Classifying topics...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [21:56<00:00, 21.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Matching complete. Results saved to 'optimized_topic_proverb_matches.csv'.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["Proverb Embeddings"],"metadata":{"id":"pFk4hekuAamj"}},{"cell_type":"code","source":["# Load the matching results\n","matches_df = pd.read_csv(\"optimized_topic_proverb_matches.csv\")\n","\n","# Initialize the \"topics\" column with empty lists\n","proverbs_df[\"topics\"] = [[] for _ in range(len(proverbs_df))]\n","\n","# Group topics by proverb\n","proverb_to_topics = matches_df.groupby(\"proverb\")[\"topic\"].apply(list).to_dict()\n","\n","# Add topics to the proverbs dataframe\n","proverbs_df[\"topics\"] = proverbs_df[\"text\"].apply(lambda proverb: proverb_to_topics.get(proverb, []))\n","\n","# Display the updated dataframe\n","print(proverbs_df.head())\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIdPKa1r7BcT","executionInfo":{"status":"ok","timestamp":1740545432094,"user_tz":360,"elapsed":22,"user":{"displayName":"Ari","userId":"13742471207560721672"}},"outputId":"2fb660cc-8415-432e-8016-e86153b5753c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["  chapter  verse                                               text      book  \\\n","0       1    1-6  The proverbs of Solomon, son of David, king of...  Proverbs   \n","1       1      7  The fear of the LORD is the beginning of knowl...  Proverbs   \n","2       1    8-9  Hear, my son, your father's instruction, and f...  Proverbs   \n","3       1  10-19  My son, if sinners entice you, do not consent....  Proverbs   \n","4       1  20-33  Wisdom cries aloud in the street, in the marke...  Proverbs   \n","\n","                                              topics  \n","0  [Academic burnout, Academic success, Academic ...  \n","1                                                 []  \n","2                                                 []  \n","3  [Birth control, Civil rights, Dating boundarie...  \n","4                                                 []  \n"]}]},{"cell_type":"markdown","source":["Model"],"metadata":{"id":"6hpp0KA_g6ie"}},{"cell_type":"code","source":["proverbs_df.to_csv(\"proverbs_topics.csv\", index=False)"],"metadata":{"id":"BgxaYsxY7mtm","executionInfo":{"status":"ok","timestamp":1740543964469,"user_tz":360,"elapsed":25,"user":{"displayName":"Ari","userId":"13742471207560721672"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Load a pretrained Sentence Transformer model\n","model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","\n","# Calculate embeddings by calling model.encode()\n","proverbs_references = (proverbs_df['book'] + ' ' + proverbs_df['chapter'] + ':' + proverbs_df['verse']).to_list() + (ecc_df['book'] + ' ' + ecc_df['chapter'] + ':' + ecc_df['verse']).to_list()\n","proverb_embeddings = model.encode(proverbs)"],"metadata":{"id":"ySX4mHSAAeHe","executionInfo":{"status":"ok","timestamp":1740543969081,"user_tz":360,"elapsed":3060,"user":{"displayName":"Ari","userId":"13742471207560721672"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Calculate embedding of query\n","prompt = input(\"Explain your quandry, and I will tell you wisdom. The more detail -> the better.\\n\\n\")\n","prompt_embedding = model.encode(prompt)\n","\n","# Calculate the embedding similarities\n","similarities = model.similarity(proverb_embeddings, prompt_embedding)\n","\n","top_values, top_indices = torch.topk(similarities, 3, dim=0)\n","\n","print(\"\\n\")\n","verse_tally=0\n","for j in range(3):\n","  ref = proverbs_references[top_indices[j][0]]\n","  print(ref)\n","  print(proverbs[top_indices[j][0]])\n","\n","  if '-' in ref:\n","    verse_tally += int(ref.split(':')[1].split('-')[1])-int(ref.split(':')[1].split('-')[0]) + 1\n","  else:\n","    verse_tally += 1\n","  if verse_tally > 2:\n","    break"],"metadata":{"id":"iIN8ScAFB4pO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740544017000,"user_tz":360,"elapsed":9625,"user":{"displayName":"Ari","userId":"13742471207560721672"}},"outputId":"fe3d093c-ae28-4a49-fb77-7295c3311725"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Explain your quandry, and I will tell you wisdom. The more detail -> the better.\n","\n","What is the meaning of life? What should I do with my time?\n","\n","\n","Ecclesiastes 3:1-8\n","For everything there is a season, and a time for every matter under heaven: a\n","time to be born, and a time to die; a time to plant, and a time to pluck up what\n","is planted; a time to kill, and a time to heal; a time to break down, and a time\n","to build up; a time to weep, and a time to laugh; a time to mourn, and a time to\n","dance; a time to cast away stones, and a time to gather stones together; a time\n","to embrace, and a time to refrain from embracing; a time to seek, and a time to\n","lose; a time to keep, and a time to cast away; a time to tear, and a time to\n","sew; a time to keep silence, and a time to speak; a time to love, and a time to\n","hate; a time for war, and a time for peace.\n","\n"]}]},{"cell_type":"markdown","source":["Experimentation for Version 4"],"metadata":{"id":"DfFo1f2b5Iab"}}]}